# PDF to JSON Parser

This project converts PDF documents into a structured JSON format, including headings, paragraphs, tables, charts, and images. It also includes a post-processing step to clean and improve the extracted JSON.

---

## 1. Set up Virtual Environment

It is recommended to use a virtual environment to manage dependencies.  

**Command to create a virtual environment:**
```bash
python -m venv venv
```

**Activate the Virtual Environment:**

- **Windows:**
```bash
venv\Scripts\activate
```

---

## 2. Install Dependencies

Install the required Python packages using `pip`:

```bash
pip install pymupdf pdfplumber pytesseract pillow camelot-py[cv] 
```

## Packages and Their Purpose

- **pymupdf**: Provides `fitz` module to read and extract text, images, and metadata from PDFs.  

- **pdfplumber**: Optional PDF parser, primarily used for table extraction when Camelot fails.  

- **pytesseract**: Python wrapper for Tesseract OCR, used to extract text from images/charts inside PDFs.  

- **pillow**: Python Imaging Library, required by `pytesseract` to handle images.  

- **camelot-py[cv]**: Extracts tables from PDFs using stream or lattice methods; `[cv]` enables OpenCV for better table detection.

---

## 3. Approach of `pdf_to_json.py`

The `pdf_to_json.py` script is the main driver that parses PDF files into structured JSON. The workflow is:

1. **Iterate through pages** of the PDF using PyMuPDF (`fitz`).  
2. **Extract text blocks and spans**, capturing font sizes and positions.  
3. **Infer headings** based on font size heuristics:  
   - Largest fonts → Section headings  
   - Slightly smaller → Sub-section headings  
4. **Extract paragraphs** and associate them with the current section/sub-section.  
5. **Extract tables**:  
   - Preferably using Camelot (stream/lattice)  
   - Fallback to pdfplumber if Camelot fails
   - Each table includes `"table_data"` and `"description": None` 
6. **Extract images**:
   - Heuristically classify as chart (if OCR detects text or image occupies significant page area) or regular image.
   - Optional OCR for charts using pytesseract.  
7. **Assemble the extracted content into a structured JSON** with the format:

```json
{
  "pages": [
    {
      "page_number": 1,
      "content": [
        {"type": "heading", "level": 1, "text": "..."},
        {"type": "paragraph", "section": "...", "sub_section": "...", "text": "..."},
        {"type": "table", "section": "...", "sub_section": "...", "description": null, "table_data": [...]},
        {"type": "chart", "section": "...", "sub_section": "...", "image_path": "...", "description": "..."},
        {"type": "image", "section": null, "sub_section": null, "image_path": "..."}
      ]
    }
  ]
}
```

---

## 4. Approach of `postprocess_json.py`

The `postprocess_json.py` script is a post-processing tool to clean the raw JSON generated by `pdf_to_json.py`.

**Purpose:**

- Remove repeated disclaimers, footers, or irrelevant text.  
- Merge fragmented short paragraphs into coherent blocks.  
- Ensure paragraphs inherit the correct section and sub-section context.

**Usage:**

The `pdf_to_json.py` script automatically calls `postprocess_json.py` after generating the raw JSON.  
The cleaned JSON is saved as `<original_filename>_cleaned.json`.

---

## 5. Running the Project

Run the parser from the command line as follows:

```bash
python pdf_to_json.py sample.pdf output.json --images-dir ./imgs
```

**Parameters:**

- `sample.pdf`: Path to the input PDF file.  
- `output.json`: Path to save the raw JSON.  
- `--images-dir ./imgs`: Directory to save extracted images/charts. Default is `extracted_images`.  
- `--ocr`: Optional flag to enable OCR for images (requires pytesseract + Tesseract).  

**Example Output:**

- **Raw JSON:** `output.json`  
- **Cleaned JSON:** `output_cleaned.json`  
- **Extracted images:** Saved in `./imgs/`

---

**Note:**  
The repository currently also contains an example of the output generated by running the parser on a sample PDF, along with all the code scripts. This is provided to help you quickly understand the structure and format of the extracted JSON.
